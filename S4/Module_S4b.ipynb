{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ranging-amplifier",
   "metadata": {},
   "source": [
    "# MATH 3350 Course Notes - Module S4 (Part II)\n",
    "\n",
    "## Hypothesis Testing for Two Proportions\n",
    "\n",
    "Recall the steps to conducting a hypothesis test:  \n",
    "1. Identify a population parameter and state null and alternative hypotheses about the parameter\n",
    "2. Create a model consistent with the NULL HYPOTHESIS\n",
    "3. Use the model to determine a p-value (the probability that results as extreme as those we observed would occur by random chance IF the null hypothesis were true)\n",
    "4. Based on the p-value, decide whether to reject the null hypothesis in favor of the alternative\n",
    "5. Draw a conclusion in the context of the scenario given  \n",
    "\n",
    "In the notes below, we will focus on how to accomplish STEPS 1-3 above using _R_.  \n",
    "\n",
    "**_Remember that to complete a hypothesis test, you should proceed to steps 4 and 5 after the p-value is found._**  \n",
    "\n",
    "### Creating the Model of the Null Hypothesis\n",
    "Recall our two 'families' of options for steps 2-3 (creating the model and finding the p-value):\n",
    "1. Use simulation/randomization to create an empirical model and find a p-value.\n",
    "2. Use a theoretical distribution to find a p-value. (There is sometimes more than one suitable theoretical distribution.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-publisher",
   "metadata": {},
   "source": [
    "### Example 1.  Dolphin Therapy\n",
    "Our hypothesis is about the \"true\" proportion of individuals who would improve if they received dolphin therapy ($p_1$), compared to the \"true\" proportion of those who would improve if dolphins were not introduced into their treatment ($p_2$). (**Note:** these parameters, $p_1$ and $p_2$, represent these true proportions across all possible patients, not just the 30 patients in the study.)  Regardless of which method above we choose to generate our p-value, our hypotheses are as follows.\n",
    "<center>\n",
    "$H_{0}: p_1 = p_2$  \n",
    "</center>\n",
    "<center>\n",
    "$H_{a}: p_1 > p_2$\n",
    "</center>\n",
    "\n",
    "Notice that another way to write these hypotheses is to focus on the **_difference_** between the proportions:  \n",
    "<center>\n",
    "$H_{0}: p_1 - p_2 = 0$  \n",
    "</center>\n",
    "<center>\n",
    "$H_{a}: p_1 - p_2 = 0$\n",
    "</center>\n",
    "\n",
    "#### Our Sample \n",
    "In the experiment, 10 of the 15 participants in the ('dolphin') treatment group improved, and 3 of the 15 participants in the control group improved. This gives us the following sample statistics:\n",
    "<center>\n",
    "    $\\widehat{p_1}=\\frac{10}{15}=0.667$\n",
    "</center>\n",
    "<center>\n",
    "    $\\widehat{p_2}=\\frac{3}{15}=0.2$\n",
    "</center>\n",
    "\n",
    "And the following _difference in sample proportions:_  \n",
    "\n",
    "<center>\n",
    "    $\\widehat{p_1} - \\widehat{p_2}=0.667-0.2=0.467$\n",
    "</center>\n",
    "\n",
    "The hypothesis test is intended to help us decide if this difference is _statistically significant_.\n",
    "\n",
    "#### Method 1 - Empirical p-value through simulation/randomization\n",
    "If the null hypothesis is true, the only explanation for the difference in results between the two groups in the experiment is that the individual's improvement had nothing to do with their treatment group. In other words, it was just random chance that the individuals who improved were in the 'dolphin' group.  \n",
    "\n",
    "Below, we show a repeated simulation of assigning the individuals randomly to treatment groups, assuming that their outcome is NOT related to their treatment group. This is our way of modeling $H_0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-powder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create array of all outcomes in study (all 30 participants), regardless of treatment group\n",
    "#Y=Participant who improved; N=Participant who did not improve\n",
    "num_improved <- 13\n",
    "num_not_improved <- 17\n",
    "\n",
    "participants <- c(rep('Y', num_improved),rep('N', num_not_improved))\n",
    "participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mimic a treatment group of size 15 being randomly selected from these 30 participants\n",
    "tgroup <- sample(participants,15,replace=FALSE)\n",
    "tgroup\n",
    "\n",
    "#How many individuals who improved were randomly placed in this group (with dolphins)?\n",
    "count1 <- sum(tgroup=='Y')\n",
    "p_hat1 <- count1/15\n",
    "\n",
    "#The remaining participants were in the other (control) group\n",
    "count2 <- num_improved - count1\n",
    "p_hat2 <- count2/15\n",
    "\n",
    "diff <- p_hat1 - p_hat2\n",
    "\n",
    "cat(\"Dolphin Group: \", count1,\" improved - sample proportion = \", p_hat1)\n",
    "cat(\"\\n\")  #new line\n",
    "cat(\"Control Group: \", count2,\" improved - sample proportion = \", p_hat2)\n",
    "cat(\"\\n\")  \n",
    "cat(\"Difference in sample proportions: \",diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeat random sampling from the participants many times \n",
    "num_trials <- 10000\n",
    "\n",
    "#This vector will hold the difference in proportions for each randomized assignment\n",
    "differences <- c()          \n",
    "\n",
    "#Create a model of the number of differences we would expect for a \n",
    "#                  random group assignment IF THE NULL HYPOTHESIS IS TRUE\n",
    "for (i in 1:num_trials){\n",
    "    tgroup <- sample(participants,15,replace=FALSE)\n",
    "    count1 <- sum(tgroup=='Y')\n",
    "    count2 <- num_improved - count1\n",
    "    differences[i] <- (count1/15 - count2/15)\n",
    "}\n",
    "\n",
    "#Visualize our model\n",
    "hist(differences, main=\"Difference in Proportion of Improved Participants (Null Model)\", breaks=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-completion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute p-value from above empirical model\n",
    "sample_diff <- (10/15 - 3/15)\n",
    "\n",
    "cat(\"Finding differences of \", sample_diff, \"or greater...\\n\")\n",
    "\n",
    "emp_p <- sum(differences>=sample_diff)/num_trials\n",
    "cat(\"Empirical p-value:\", emp_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spare-profit",
   "metadata": {},
   "source": [
    "#### Method 2 - Theoretical Distribution\n",
    "\n",
    "#### Normal Distribution (z-Test for 2 Proportions)\n",
    "\n",
    "Under some circumstances, it would be appropriate to use a z-Test (approximation with a Normal distribution). Again, there are conditions that should be met for this approach to be viable:\n",
    "\n",
    "1. $\\widehat{p_1}n_1 \\geq 10 $\n",
    "2. $(1-\\widehat{p_1})n_1 \\geq 10 $ \n",
    "3. $\\widehat{p_2}n_2 \\geq 10 $\n",
    "4. $(1-\\widehat{p_2})n_2 \\geq 10 $ \n",
    "\n",
    "In other words, there should be at least 10 'successes' and 10 'failures' in **_each_** sample group.  The Dolphin Therapy study does not meet these conditions.  \n",
    "\n",
    "#### Chi-Square Distribution\n",
    "The $\\chi^{2}$ family of distributions can be used to test the _independence_ of two variables. Consider our data, summarized in a _contingency table_ as follows:  \n",
    "\n",
    "| Treatment | Improved  | Not Improved |\n",
    "|-----------|-----------|--------------|\n",
    "| Dolphins | 10 | 5 |\n",
    "| No Dolphins | 3 | 12 |\n",
    "\n",
    "The two variables are **_Treatment_** and **_Improvement_**, represented by counts in the rows and columns, respectively.  \n",
    "\n",
    "The hypotheses are stated differently in a $\\chi^{2}$ Test of Independence:  \n",
    "\n",
    "\n",
    "$H_0:$ _Improvement_ and _Treatment_ are INDEPENDENT  \n",
    "$H_a:$ _Improvement_ and _Treatment_ are NOT INDEPENDENT\n",
    "\n",
    "##### Expected Counts \n",
    "If the null hypothesis is accurate, we would _expect_ the proportion of improved/not improved to be the same in both groups.  The $\\chi^{2}$ Test uses the OVERALL proportions in the sample data to compute \"expected counts\" that would ideally occur if the 2 variables were truly independent (e.g., we would expect the same proportion of individuals to improve, regardless of group).  \n",
    "\n",
    "Here is an example of an expected count calculation:  \n",
    "\n",
    "$\\frac{13}{30} \\approx 0.433$ is the overall proportion of participants who improved.  \n",
    "\n",
    "Therefore, if $H_0$ is true, we would expect $\\sim 43.3$% of the individuals in EACH group to improve; because there are 15 participants in the Dolphin group, this would be an _expected count_ of $(0.433)(15) = 6.5$.  \n",
    "\n",
    "Here is a table of all **expected counts** for this scenario:  \n",
    "\n",
    "| Treatment | Improved  | Not Improved |\n",
    "|-----------|-----------|--------------|\n",
    "| Dolphins | 6.5 | 8.5 |\n",
    "| No Dolphins | 6.5 | 8.5 |\n",
    "\n",
    "##### The $\\chi^{2}$ Statistic \n",
    "\n",
    "The $\\chi^{2}$ statistic is a measure of how much the _observed_ counts differ from the _expected_ counts. It is computed across all cells in the table as:  \n",
    "\n",
    "<center>\n",
    "$\\chi^{2} = \\sum \\frac{(observed-expected)^{2}}{expected}$\n",
    "</center>\n",
    "\n",
    "For our example, \n",
    "\n",
    "<center>\n",
    "$\\chi^{2} = \\frac{(10-6.5)^{2}}{6.5} + \\frac{(3-6.5)^{2}}{6.5} + \\frac{(5-8.5)^{2}}{8.5} + \\frac{(12-8.5)^{2}}{8.5} \\approx 6.652$\n",
    "</center>\n",
    "\n",
    "The number of data rows and columns in the contingency table defines the **degrees of freedom** of the $\\chi^{2}$ distribution we will use to find our p value.  \n",
    "\n",
    "<center>\n",
    "$df=(rows - 1)(columns - 1)$\n",
    "</center>\n",
    "\n",
    "Without any labels, our DATA table has 2 rows and 2 columns:\n",
    "\n",
    "| | | \n",
    "|-----------|-----------|\n",
    "| 10 | 5 |\n",
    "| 3 | 12 |\n",
    "\n",
    "Therefore we need the $\\chi^{2}$ distribution with $df = 1$.  Remember that this is the distribution of $\\chi^{2}$ statistics we would expect from samples if the null hypothesis were true.  Below we visualize this distribution so we can see where our $\\chi^{2}$ statistic falls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize chi-square distribution with df=1\n",
    "\n",
    "xvalues <- seq(0,15,0.1)     \n",
    "yvalues <- dchisq(xvalues, df=1)\n",
    "\n",
    "plot (xvalues,yvalues, main=\"PDF of Chi-Square Distribution, df=1\", \n",
    "      xlab=\"Chi-Square Statistic\", ylab=\"Density\", type=\"l\")\n",
    "\n",
    "#Add a line to show where the chi-square value of our sample is\n",
    "abline(v=6.652, lty=2, col=\"red\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-wiring",
   "metadata": {},
   "source": [
    "##### Interpreting the $\\chi^{2}$ Statistic\n",
    "The larger the $\\chi^{2}$ statistic, the greater the discrepancy between observed and expected counts. Our p-value should represent the probability of a $\\chi^{2}$ value _at least as extreme_ as the one produced by our sample. Therefore, we want the area under the curve to the _right_ of our $\\chi^{2}$ of 6.652."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find our pvalue from the above distribution (right tail)\n",
    "theory_p <- pchisq(6.652,df=1,lower.tail=FALSE)\n",
    "cat(\"Theoretical p-value (chi-square): \", theory_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-insight",
   "metadata": {},
   "source": [
    "#### Method 2 - Theoretical Distribution (Option B)\n",
    "R will also perform a test based on the $\\chi^{2}$ distribution.  This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chi-square hypothesis test\n",
    "\n",
    "#Create matrix of data set\n",
    "data_tbl <- matrix(c(10,5,3,12), ncol=2, byrow=TRUE)\n",
    "colnames(data_tbl) <- c('Improved', 'Not Improved')\n",
    "rownames(data_tbl) <- c('Dolphins', 'No Dolphins')\n",
    "\n",
    "#View matrix\n",
    "data_tbl\n",
    "\n",
    "#Perform test on matrix (without correction factor to match test we did by hand)\n",
    "cs_test <- chisq.test(data_tbl,correct=FALSE)\n",
    "\n",
    "#Results of test are now stored in variable called cs_test\n",
    "\n",
    "#View expected counts\n",
    "cat(\"Expected Counts:\")\n",
    "cs_test$expected\n",
    "\n",
    "#View test result\n",
    "cs_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
